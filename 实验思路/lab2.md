# Lab2

首先该算法核心成员是:领导者，跟随着以及候选者三种身份，日志条目仅从领导者流向其他服务器。Raft 使用随机定时器来选举领导者。还有一个很关键的概念，
复制状态机：复制状态机被用于解决分布式系统中的多种容错问题。例如，许多依赖单一集群领导者的大型系统，通常使用一个独立的复制状态机来管理领导者选举，
并存储必须在领导者崩溃后仍然可用的配置信息。复制状态机通常通过一个复制日志来实现。每个服务器都存储一个包含一系列命令的日志，其状态机会按顺序执行这些
命令。每份日志都包含相同的命令且顺序一致，因此每台状态机会处理相同的命令序列。由于状态机是确定性的，它们会计算出相同的状态和相同的输出序列。保持复制
日志的一致性是共识算法的工作。服务器上的共识模块接收来自客户端的命令，并将其添加到日志中。它通过与其他服务器上的共识模块通信，确保每份日志最终都包含
相同的请求并以相同的顺序排列，即使某些服务器发生故障也是如此。当命令被正确复制后，每台服务器的状态机会按日志顺序处理这些命令， 并将输出返回给客户端。
最终，这些服务器对外表现为一个高度可靠的单一状态机。Raft是一种用于管理复制日志的算法，Raft 通过首先选举出一个领导者来实现共识，然后赋予领导者完全
的责任来管理复制日志。领导者负责从客户端接收日志条目,将它们复制到其他服务器，并告知这些服务器何时可以将日志条目安全地应用到它们的状态机中。leader
和follower之间通信主要有两个方法一个是AppendEntries另一个是RequestVote, AppendEntries有两个作用一个是同步日志另一个是发送心跳，发送心跳的
时候，其中要同步的日志条目就为空,会先判断当前的任期是不是大于或等于接收者的任期，如果小于那么接收者会返回false。Leader 通过 AppendEntries 消息
定期发送心跳信号，确保 Follower 知道当前 Leader，并防止 Follower 触发选举。当有新的日志条目产生时，Leader 会将其复制到 Follower。Leader 
等待大多数 Follower 的确认后，将日志条目标记为已提交 （通过更新 commitIndex）。Follower 接收到更新的commitIndex后，将日志条目应用到状态机，
保持状态一致性。 

当领导者选举完成，它开始处理客户端请求。每个客户端请求包含一个命令，供复制的状态机执行。领导者将命令作为新条目追加到自己的日志中，然后并行向集群中
的其他服务器发送 AppendEntries RPC来复制该条目。当条目被安全地复制后，领导者将该条目应用到自己的状态机，并将执行结果返回给客户端。如果跟随者崩溃
或运行缓慢，或者网络数据包丢失，领导者会无限期地重试 AppendEntries RPC（即使它已经向客户端返回了响应），直到所有的跟随者最终存储所有日志条目。日
志条目中的任期号用于检测日志之间的不一致性.每个日志条目还具有一个整数索引，用来标识它在日志中的位置。领导者决定何时可以安全地将日志条目应用到状态机，
这样的条目称为已提交条目。**Raft 保证已提交的条目是持久的，并最终会被所有可用的状态机执行。**一旦创建该条目的领导者将其复制到大多数服务器上，该条
目就会被提交.这也会提交领导者日志中的所有前置条目，包括由前一个领导者创建的条目。

领导者会跟踪它知道的最高已提交条目的索引，并将该索引包含在未来的 AppendEntries RPC 中（包括心跳），以便其他服务器最终得知。一旦跟随者得知某个日
志条目已提交，它会按日志顺序将该条目应用到本地状态机。如果不同日志中的两个条目具有相同的索引和任期，则它们存储相同的命令。如果不同日志中的两个条目具
有相同的索引和任期，则它们在所有前置条目中的内容完全相同。在正常操作中，领导者和跟随者的日志保持一致，因此 AppendEntries 一致性检查不会失败。然而
领导者崩溃可能导致日志不一致（旧领导者可能没有完全复制日志中的所有条目）。这些不一致性可能会在一系列领导者和跟随者崩溃后加剧.在 Raft中，领导者通过
强制跟随者的日志与其自己的日志一致来处理不一致性。这意味着，跟随者日志中的冲突条目将被领导者日志中的条目覆盖。为了使跟随者的日志与自己的日志一致，领
导者必须找到两个日志中最新的相同条目，然后删除跟随者日志中该条目之后的所有条目，并将领导者在此之后的所有条目发送给跟随者。所有这些操作都在 AppendE
ntries RPC 执行一致性检查时发生。领导者为每个跟随者维护一个 nextIndex，该值表示领导者将发送给该跟随者的下一个日志条目的索引。当领导者首次上任时
，它会将所有的 nextIndex 值初始化为它日志中最后一个条目之后的索引。如果跟随者的日志与领导者的日志不一致，AppendEntries 一致性检查将在下一次 A
ppendEntries RPC 中失败。在拒绝后，领导者会将 nextIndex 值减小，并重试 AppendEntries RPC。最终，nextIndex 会到达一个点，在该点领导者和
跟随者的日志将匹配。当发生这种情况时，AppendEntries 将成功执行，从而删除跟随者日志中的任何冲突条目，并附加领导者日志中的条目（如果有）。一旦 App
endEntries 成功，跟随者的日志将与领导者的日志一致，并且在该任期内将保持一致。如果需要，可以优化协议以减少拒绝的 AppendEntries RPC 数量。例如，
当拒绝一个 AppendEntries 请求时，跟随者可以包含冲突条目的任期和该任期的第一个条目的索引。有了这些信息，领导者可以减少 nextIndex，以跳过该任期中
的所有冲突条目；这样，每个有冲突条目的任期只需要一次 AppendEntries RPC，而不是每个条目都需要一次 RPC。通过这个机制，领导者在上任时不需要采取任何
特别的措施来恢复日志一致性。它只需要开始正常操作，日志会自动在 AppendEntries 一致性检查的响应中趋于一致。领导者永远不会覆盖或删除自己日志中的条目：
只要大多数服务器处于正常状态，Raft 就可以接受、复制和应用新的日志条目；在正常情况下，一个新的条目可以通过一次对集群大多数服务器的 RPC 来完成复制；
一个慢速跟随者不会影响性能。
## Part A

### 踩坑 ： 
1. 当选举人的任期必须要大于被选举的任期，不能等于，等于会造成 双leader情况(两个节点同时超时,那么他们会同时增加任期,此时如果他们又同时发送选举请求给对方,如果任期相等也同意的话,那么两人都会得到对方的选票,此时,如果总共有三个节点,那么他们两个节点都得到超过半数的选票,同时成为leader)
2. 当两个都是候选者，低任期应该为高任期投票
3. 应该避免锁住多个函数调用,这样会造成延迟,当A 节点发送给B节点心跳,由于这个原因导致B节点接收到心跳就超时了
4. 死锁的发生 由于一个函数调用多个函数且都使用了 defer unlock 函数调用导致了死锁,当用协程 启动另一个有锁的函数时,不会死锁


### 实现思路
实现 Raft 的领导者选举和心跳功能（AppendEntries RPC 不携带日志条目）。2A 部分的目标是确保系统能够选出一个领导者，
在没有故障的情况下领导者能够持续担任其角色，并且当旧的领导者失效或通信丢失时，新领导者能够接任

理清代码逻辑：首先就是在创建好一个节点后，该节点的状态应该为候选者，然后选举间隔，如果在选举间隔时间超时前收到领导者心跳那么就变为跟随着，如果超时没收到，
那么发起选举，这时候又有多种情况，如果得到半数的选票，那么成为领导者，并立刻发送心跳给跟随者，收到心跳的跟随者应该也重置选举间隔和心跳检测 。如果没
有收到半数的选票，并且收到比自己节点大的任期应该更新自己的任期为更大任期，并转为跟随者(PartA是这样,后面部分应该加入判断)。


## Part B

### 踩坑:
1. 还是死锁的产生
2. Start 函数必须实现,他是测试用的,在append日志的时候,日志的任期要等于当前任期
3. 需要想applyCh chan ApplyMsg 传入ApplyMsg结构体的信息,就是传入命令和命令存储在日志的下标以及该命令是否有效,共测试调用,刚开始没有实现,导致测试的时候一直为空
4. 日志复制和心跳发起的时候领导者节点，没有重置选举定时器，有错误， 查看测试过程是 首先节点2成了领导者，然后任期是1，只有一个日志,101并复制给从节点,从节点接受日志
领导者的commit就是1了，从节点commit也更新为1.然后领导者节点2断开连接，并有添加了三个日志 分别是102，103，104.之后节点0，1都同时向对方发起选举，结果没有选出来
但是 他们的任期都加1，当前两个任期都是2了。随后节点1对节点0发起选举，成功当选领导者，然后加入了日志103此时节点1有两个日志{101，103}.随后复制给节点0，节点0
当前日志是{101，103},且103任期是3，且commit都更新为2，随后断开1领导者，连入节点2，旧领导者。且节点2再加入了日志104，此时有五个日志{101，102，103，104，104}
然后向节点0发起日志复制，但是任期过小，复制失败。但是更新了自己的任期是3，那么他会发起选举，任期变成4，那么这个落后的领导者会重新成为领导者导致出错。

### 改正
1. 对第五点的改正是，取消领导者选举定时器重置（不取消也可以，但没用）,删除日志复制失败后，返回的任期比当前任期大的情况下，不能更新自己的任期,但是这样似乎保存的不是最新的任期?
所以应该在发起日志复制后开启充值选举定时器,这样的话,另一个节点必然比当前节点早开启选举


### 实现思路


1. 实验要求是你需要去进行日志复制,比如领导者得到日志,加入自己的日志数组中,然后应该再去复制这个日志给从节点,让他们知道,当前索引下标应该存储这个日志
当,大多数节点存储了,领导者节点应该提交这个日志
2. 那么当从节点接收到领导者发来的日志复制请求时,应该先重置自己的选举定时器,这在实验一就已经实现了,那么应该判断任期是否比自己大,小于自己返回false即可
大于自身的话,更新自己的任期,然后判断PrevLogIndex 如果大于当前节点的最大索引,大于了,应该返回false,并将自己的最大索引返回回去,这样,下次日志复制的PrevLogIndex
就是你的最大索引,在进行进一步判断,如果当前PrevLogIndex下标的任期也一致,那么开始复制或者append日志,重复的部分直接覆盖即可,越界的不返增添即可.
此时如果发现领导者节点的提交索引大于当前的,那么应该去更新自己的提交索引,并唤醒等待的应用线程(sendMsgToTester).那么如果任期不一致,那么,从节点应该去遍历自己的日志,直到遍历了一个不一样任期的索引,然后返回下标和任期,再做判断.
3. 然后就是领导者选举应该进行修改,不能单单由于任期大就选择它作为领导者,因为存在一种情况,他断开了连接,导致他不停的去开启选举,增加自己的任期,但他存储的日志
可能非常少,因为在断链的这段时间,没有日志的添加.所以,当选举时遇到比自己任期大的(小于自己的还是直接返回false),先复制他的任期,
并判断日志的最后一个的任期,相同还要进一步判断日志的最后一个的索引大与自己与否
4. 成为领导者的时候应该将从节点的commitIndex设置为0,NextIndex设置为 最大索引加一



## Part C

### 要求
1. 在Raft论文的图2中，有且仅有三个数据是需要持久化存储的。它们分别是Log、currentTerm、votedFor。Log是所有的Log条目。当某个服务器刚刚重启，在
它加入到Raft集群之前，它必须要检查并确保这些数据有效的存储在它的磁盘上。服务器必须要有某种方式来发现，自己的确有一些持久化存储的状态，而不是一些无意义的数据。
2. Log需要被持久化存储的原因是，这是唯一记录了应用程序状态的地方。
3. currentTerm和votedFor都是用来确保每个任期只有最多一个Leader。在一个故障的场景中，如果一个服务器收到了一个RequestVote请求，并且为服务器1
投票了，之后它故障。如果它没有存储它为哪个服务器投过票，当它故障重启之后，收到了来自服务器2的同一个任期的另一个RequestVote请求，那么它还是会投票
给服务器2，因为它发现自己的votedFor是空的，因此它认为自己还没投过票。现在这个服务器，在同一个任期内同时为服务器1和服务器2投了票。因为服务器1和服
务器2都会为自己投票，它们都会认为自己有过半选票（3票中的2票），那它们都会成为Leader。现在同一个任期里面有了两个Leader。这就是为什么votedFor必须
被持久化存储。
4. currentTerm的情况要更微妙一些，但是实际上还是为了实现一个任期内最多只有一个Leader，
我们之前实际上介绍过这里的内容。如果（重启之后）我们不知道任期号是什么，很难确保一个任期内只有一个Leader。
5. 这些数据需要在每次你修改它们的时候存储起来。可以确定的是，安全的做法是每次你添加一个Log条目，更新currentTerm或者更新votedFor，你或许都需要
持久化存储这些数据。在一个真实的Raft服务器上，这意味着将数据写入磁盘，所以你需要一些文件来记录这些数据。如果你发现，直到服务器与外界通信时，才有可
能持久化存储数据，那么你可以通过一些批量操作来提升性能。例如，只在服务器回复一个RPC或者发送一个RPC时，服务器才进行持久化存储，这样可以节省一些
持久化存储的操作。
6. 另一个常见方法是，批量执行操作。如果有大量的客户端请求，或许你应该同时接收它们，但是先不返回。等大量的请求累积之后，一次性持久化存储（比如）100个
Log，之后再发送AppendEntries。如果Leader收到了一个客户端请求，在发送AppendEntries RPC给Followers之前，必须要先持久化存储在本地。因为Leader
必须要commit那个请求，并且不能忘记这个请求。实际上，在回复AppendEntries 消息之前，Followers也需要持久化存储这些Log条目到本地，因为它们最终也要
commit这个请求，它们不能因为重启而忘记这个请求。



### 例子

#### 解释 3,4点
S1关机了，S2和S3会尝试选举一个新的Leader。它们需要证据证明，正确的任期号是8，而不是6。如果仅仅是S2和S3为彼此投票，它们不知道当前的任期号，它们只 
能查看自己的Log，它们或许会认为下一个任期是6（因为Log里的上一个任期是5）。如果它们这么做了，那么它们会从任期6开始添加Log。但是接下来，就会有问题
了，因为我们有了两个不同的任期6（另一个在S1中）。这就是为什么currentTerm需要被持久化存储的原因，因为它需要用来保存已经被使用过的任期号。


###  实验思路
1. 再更改Log、currentTerm、votedFor地方 持久化即可


## PartD

### 背景
#### 为什么要日志压缩和快照
Log压缩和快照解决的问题是：对于一个长期运行的系统，例如运行了几周，几个月甚至几年，如果我们按照Raft论文图2的规则，那么Log会持续增长。最后可能会有
数百万条Log，从而需要大量的内存来存储。如果持久化存储在磁盘上，最终会消耗磁盘的大量空间。如果一个服务器重启了，它需要通过重新从头开始执行这数百万条
Log来重建自己的状态。当故障重启之后，遍历并执行整个Log的内容可能要花费几个小时来完成。这在某种程度上来说是浪费，因为在重启之前，服务器已经有了一定
的应用程序状态。
#### 快照的概念
快照背后的思想是，要求应用程序将其状态的拷贝作为一种特殊的Log条目存储下来。如果Raft要求应用程序做一个快照，Raft会从Log中选取一个与快照对应的点，
然后要求应用程序在那个点的位置做一个快照。这里极其重要，因为我们接下来将会丢弃所有那个点之前的Log记录。如果我们有一个点的快照，那么我们可以安全的将那
个点之前的Log丢弃。（在key-value数据库的例子中）快照本质上就是key-value表单。

### 实验相关
#### 节点重启后的操作
重启的时候会发生什么呢？现在，重启的场景比之前只有Log会更加复杂一点。重启的时候，必须让Raft有方法知道磁盘中最近的快照和Log的组合，并将快照传递给
应用程序。因为现在我们不能重演所有的Log（部分被删掉了），所以必须要有一种方式来初始化应用程序。所以应用程序不仅需要有能力能生成一个快照，它还需要
能够吸纳一个之前创建的快照，并通过它稳定的重建自己的内存。所以，尽管Raft在管理快照，快照的内容实际上是应用程序的属性。Raft并不理解快照中有什么，
只有应用程序知道，因为快照里面都是应用程序相关的信息。所以重启之后，应用程序需要能够吸纳Raft能找到的最近的一次快照。
#### 引入快照的复杂性
这里丢弃了快照之前的Log，引入了大量的复杂性。如果有的Follower的Log较短，在Leader的快照之前就结束，那么除非有一种新的机制，否则那个Follower永远
也不可能恢复完整的Log。因为，如果一个Follower只有前两个槽位的Log，Leader不再有槽位3的Log可以通过AppendEntries RPC发给Follower，Follower
的Log也就不可能补齐至Leader的Log。
#### 解决方案

如果Leader发现有任何一个Follower的Log落后于Leader要做快照的点，那么Leader就不丢弃快照之前的Log。Leader原则上是可以知道Follower的Log位置，
然后Leader可以不丢弃所有Follower中最短Log之后的本地Log。这或许是一个短暂的好方法，之所以这个方法不完美的原因在于，如果一个Follower关机了一周，
它也就不能确认Log条目，同时也意味着Leader不能通过快照来减少自己的内存消耗（因为那个Follower的Log长度一直没有更新）。所以，Raft选择的方法是，Le
ader可以丢弃Follower需要的Log。所以，我们需要某种机制让AppendEntries能处理某些Follower的Log的结尾到Leader的Log开始之间丢失的这一段Log。解决
方法是（一个新的消息类型）InstallSnapshot RPC。当Follower刚刚恢复，如果它的Log短于Leader,通过 AppendEntries RPC发给它的内容，那么它首先会
强制Leader回退自己的Log。在某个点，Leader将不能再回退，因为它已经到了自己Log的起点。这时，Leader会将自己的快照发给Follower，之后立即通过Appe
ndEntries将后面的Log发给Follower。


#### 流程
Raft的解决方案：InstallSnapshot RPC
Raft通过引入 InstallSnapshot RPC 解决快照截断后的日志同步问题。以下是其核心流程：

1. Leader检测到Follower日志落后,Leader为每个Follower维护nextIndex（下一次要发送的日志索引）。例如，某Follower的 nextIndex=500，而Leader的快照起始索引为
index=1000。当 nextIndex < 快照起始索引 时，说明Follower需要快照。
2. 发送快照,Leader通过 InstallSnapshot RPC 发送以下信息:LastIncludedIndex：快照的最后日志索引（如 1000）。
LastIncludedTerm：该索引对应的日志任期。快照数据：序列化的状态机数据。
3. Follower处理快照:Follower收到快照后：
比较快照新旧：若 LastIncludedIndex > 自身日志长度，则接受快照。
截断日志：丢弃所有现有日志，保留快照后的日志（若有）。
更新状态：设置 commitIndex = lastApplied = LastIncludedIndex。
应用快照：将快照数据加载到状态机。
持久化：保存快照元数据（LastIncludedIndex、LastIncludedTerm）。
4. 继续日志同步
Leader更新该Follower的 nextIndex = LastIncludedIndex + 1（如 1001）。后续通过 AppendEntries 发送 index=1001 及之后的日志。

### 踩坑
1. 任期一致返回0,原因是忘记再最开始初始化返回值的任期为当前任期,导致一些情况返回任期为默认值0 
2. 当一个节点关闭长时间重新启动后,由于我并没有设置lastApplied的值为快照的
索引值,导致接受日志后,更新自己commitIndex后,调用tryApply函数时,超过lastApplied
太多,导致panic
3. 有种情况:firstlogIndex >lastlogIndex时,获取最后的日志任期时,应该返回快照的最大任期,否则
在领导者选举时候,getLastEntryTerm返回-1,从而得出鹿后的领导者
### 实验思路
实验主要是实现 快照和日志压缩.三个关键属性:快照数据,快照的最大索引和任期

1. 需要实现Snapshot这个是test需要使用的,参数是快照的最大索引以及快照,作用是把快照同步给从节点,首选传入的参数分别是,快照和快照的最大索引.
所以,我们需要判断这个快照的最大索引是否大于自己的firstLogIndex,如果大于那么说明这个快照是更新的,就要更新自己快照,并更新相应字段.并更新自己的firstLogIndex
.以及提交索引和应用索引,然后将快照发送到相应从节点.从节点接受到快照时,也要进行相应判断.比如任期小于自己的返回,大于自己的更新自己任期.以及快照的索引
是否大于当前自己快照的索引等.当快照索引大于自身快照索引,应该去更新快照,并根据是否大于自己的最大索引,来缩短日志
2. 复制日志时,如果nextIndex小于快照索引,直接发送快照即可.如果当前节点的日志是空,那么也应该发送快照,应该
这个可能是刚生产了快照,或者节点刚启动的时候.
3. 持久化加入对快照和快照最大索引的持久化.在节点启动时,也应该更新好自己的lastApplied为快照的最大索引




